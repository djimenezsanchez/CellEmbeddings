# Unsupervised Learning of Contextual Information in Multiplex Immunofluorescence Tissue Cytometry
New machine learning models designed to capture the histopathology of tissues should account not only for the phenotype and morphology of the cells but also learn complex spatial relationships between them. To achieve this, we represent the tissue as an interconnected graph, where previously segmented cells become nodes of the graph. Then the relationships between cells are learned and embedded into a low-dimensional vector, using a Graph Neural Network. This is a fully unsupervised method that learns how to optimally encode cell phenotypes, morphologies, and cell-to-cell interactions from histological tissues labeled using multiplex immunohistochemistry. We provide real multispectral images of human lung adenocarcinoma tissue samples and the code that generates contextual embeddings for each cell tissue. This framework solves limitations of previous image understanding methods whose data representation strategies are either inappropriate for Machine Learning or do not properly capture the interaction between cells. This may render next-generation image understanding deep learning frameworks predicting clinically relevant patient-level labels.

<div align="center">
  <img width="90%" alt="Contextual cell embeddings" src="https://github.com/djimenezsanchez/Contextual_cell_embeddings/blob/main/Method_Description.gif">
</div>
